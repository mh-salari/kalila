{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mksaad/sentiment-analysis-in-arabic-tweets-using-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.create_sqlite_db import DimnaDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(db_path):\n",
    "\n",
    "    with DimnaDatabase(db_path) as db:\n",
    "        records = db.ratings()\n",
    "\n",
    "    num_negative = 0\n",
    "    num_moderate = 0\n",
    "    num_positive = 0\n",
    "    comments = list()\n",
    "    labels = list()\n",
    "    for idx, (_,comment, rating)  in enumerate(records[2:]):\n",
    "        if rating == 0:\n",
    "            num_negative +=1\n",
    "            comments.append(comment)\n",
    "            labels.append(\"negative\")\n",
    "        elif rating == 2.5:\n",
    "            comments.append(comment)\n",
    "            labels.append(\"moderate\")\n",
    "            num_moderate +=1\n",
    "        elif rating == 5:\n",
    "            comments.append(comment)\n",
    "            labels.append(\"positive\")\n",
    "            num_positive +=1\n",
    "\n",
    "    num_total = len(comments)\n",
    "    \n",
    "    print(f\"Number of negative data: {num_negative} [{100*num_negative/num_total:0.2f}%]\")\n",
    "    print(f\"Number of moderate data: {num_moderate} [{100*num_moderate/num_total:0.2f}%]\")      \n",
    "    print(f\"Number of positiv  data: {num_positive} [{100*num_positive/num_total:0.2f}%]\")\n",
    "    print(f\"Total number of ratings: {num_total}\")\n",
    "    print(\"\\n\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(comments, labels, test_size=0.15, random_state=42)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sa(n, my_classifier, name, my_data):\n",
    "    x_train, y_train, x_test, y_test = my_data\n",
    "    print('parameters')\n",
    "    print('n grams:', n)\n",
    "    print('classifier:', my_classifier.__class__.__name__)\n",
    "    print('------------------------------------')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(min_df=0.0001, max_df=0.95,\n",
    "                                 analyzer='word', lowercase=False,\n",
    "                                 ngram_range=(1, n))),\n",
    "        ('clf', my_classifier),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    feature_names = pipeline.named_steps['vect'].get_feature_names()\n",
    "\n",
    "    y_predicted = pipeline.predict(x_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(metrics.classification_report(y_test, y_predicted,\n",
    "                                        target_names=['negative', 'moderate', \"positive\"]))\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)\n",
    "    print('# of features:', len(feature_names))\n",
    "    print('sample of features:', random.sample(feature_names, 40))\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted', zero_division=1)\n",
    "    recall =  recall_score(y_test, y_predicted, average='weighted', zero_division=1)\n",
    "    return name, n, accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ngrams = (1, 2, 3)\n",
    "results = []\n",
    "db_path = \"database/dimna.db\"\n",
    "classifiers = [LinearSVC(),\n",
    "               #SVC(),\n",
    "               MultinomialNB(),\n",
    "               BernoulliNB(),\n",
    "               SGDClassifier(),\n",
    "               DecisionTreeClassifier(max_depth=5),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               KNeighborsClassifier(3)]\n",
    "\n",
    "dataset = load(db_path)\n",
    "\n",
    "for g in ngrams:\n",
    "    for alg in classifiers:\n",
    "        alg_name = alg.__class__.__name__\n",
    "        r = do_sa(g, alg, alg_name, dataset)\n",
    "        results.append(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0:30}{1:9}{2:10}{3:11}{4:10}'.format('algorithm', 'ngram', 'accuracy', 'precision', 'recall'))\n",
    "print('---------------------------------------------------------------------')\n",
    "for r in results:\n",
    "    print('{0:25}{1:10}{2:10.3f}{3:10.3f}{4:10.3f}'.format(r[0], r[1], r[2], r[3], r[4]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
